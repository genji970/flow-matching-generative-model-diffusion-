{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdiffeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd2muq9yjyS7",
        "outputId": "f2d82bb4-54a5-4364-dab6-37447d87580c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.12/dist-packages (0.2.5)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from torchdiffeq) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from torchdiffeq) (1.16.1)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy>=1.4.0->torchdiffeq) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())   # True여야 GPU 사용 가능\n",
        "print(torch.cuda.device_count())   # GPU 개수\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNvjknzAj9o6",
        "outputId": "5f95f305-b285-4a67-a502-0850b414fc2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)                  # Python random 고정\n",
        "    np.random.seed(seed)               # Numpy random 고정\n",
        "    torch.manual_seed(seed)            # PyTorch CPU 고정\n",
        "    torch.cuda.manual_seed(seed)       # PyTorch GPU 단일 고정\n",
        "\n",
        "    # 연산 재현성 보장 (속도는 약간 손해봄)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "XToncjsgw2s7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize((0.5,), (0.5,)),  # [-1,1] 범위\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # [-1,1] 범위\n",
        "    #transforms.Lambda(lambda x: x.view(-1))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "subset = Subset(train_dataset, range(1000))\n",
        "train_loader = DataLoader(subset, batch_size=16, shuffle=True)\n",
        "\n",
        "val_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "val_subset = Subset(val_dataset, range(500))\n",
        "val_loader = DataLoader(val_subset, batch_size=16, shuffle=False)\n",
        "\n",
        "dim = 256  # 3072\n",
        "\n",
        "# --------------------------------------\n",
        "# 2. 벡터장 모델\n",
        "# --------------------------------------\n",
        "# CNN 기반 Vector Field\n",
        "class ConvVectorField(nn.Module):\n",
        "    def __init__(self, hidden_dim=32):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.conv1 = nn.Conv2d(3+1, hidden_dim, 3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, 3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(hidden_dim, hidden_dim*4, 3, stride=2, padding=1)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.res1 = nn.Conv2d(hidden_dim*4, hidden_dim*4, 3, padding=1)\n",
        "        self.res2 = nn.Conv2d(hidden_dim*4, hidden_dim*4, 3, padding=1)\n",
        "\n",
        "        # Decoder\n",
        "        self.deconv1 = nn.ConvTranspose2d(hidden_dim*4, hidden_dim*4, 4, stride=2, padding=1)\n",
        "        self.deconv2 = nn.ConvTranspose2d(hidden_dim*4, hidden_dim, 4, stride=2, padding=1)\n",
        "        self.conv_out = nn.Conv2d(hidden_dim, 3, 3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # x: (B, 3, 32, 32), t: (B,1)\n",
        "        B, _, H, W = x.shape\n",
        "        xt = torch.cat([x, t], dim=1)         # (B, 4, 32, 32)\n",
        "\n",
        "        # Encoder\n",
        "        h = F.relu(self.conv1(xt))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = F.relu(self.conv3(h))\n",
        "\n",
        "        # Bottleneck (Residual style)\n",
        "        h = F.relu(self.res1(h)) + h\n",
        "        h = F.relu(self.res2(h)) + h\n",
        "\n",
        "        # Decoder\n",
        "        h = F.relu(self.deconv1(h))\n",
        "        h = F.relu(self.deconv2(h))\n",
        "        out = self.conv_out(h)   # (B,3,32,32)\n",
        "        return out\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# 3. Flow Matching Loss\n",
        "# --------------------------------------\n",
        "def flow_matching_loss(model, x0, x1, t):\n",
        "    xt = (1 - t) * x0 + t * x1   # (B,3,32,32)\n",
        "    ut_target = x1 - x0\n",
        "    input_t = t.mean(dim=1, keepdim=True)\n",
        "    ut_pred = model(xt, input_t)       # CNN 결과도 (B,3,32,32)\n",
        "    return ((ut_pred - ut_target) ** 2).mean()\n",
        "\n",
        "# --------------------------------------\n",
        "# 4. 학습 루프\n",
        "# --------------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ConvVectorField(dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "epochs = 100\n",
        "losses = []\n",
        "val_losses = []\n",
        "accumulation_steps = 4\n",
        "\n",
        "checkpoint_dir = \"./checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch_idx, (images, _) in enumerate(train_loader):\n",
        "        x1 = images.to(device)                    # target = CIFAR image\n",
        "        x0 = torch.randn_like(x1).to(device)      # source = Gaussian\n",
        "        t = torch.rand(x1.shape[0], 1).to(device)     # time ∈ [0,1]\n",
        "        t = t.view(-1, 1, 1, 1).expand(-1, x1.shape[1], x1.shape[2], x1.shape[3])\n",
        "\n",
        "        loss = flow_matching_loss(model, x0, x1, t)\n",
        "\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        # 🔹 일정 step마다 optimizer 갱신\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # ---- Validation ----\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, _ in val_loader:\n",
        "            x1 = images.to(device)\n",
        "            x0 = torch.randn_like(x1).to(device)\n",
        "            t = torch.rand(x1.shape[0], 1).to(device)\n",
        "            t = t.view(-1, 1, 1, 1).expand(-1, x1.shape[1], x1.shape[2], x1.shape[3])\n",
        "            val_loss = flow_matching_loss(model, x0, x1, t)\n",
        "            val_running_loss += val_loss.item()\n",
        "\n",
        "    avg_val_loss = val_running_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # 🔹 Best checkpoint 저장 (val_loss 기준)\n",
        "    if epoch == 0:\n",
        "        best_val_loss = avg_val_loss\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        ckpt_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
        "        torch.save({\n",
        "        \"epoch\": epoch+1,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"loss\": loss.item(),\n",
        "        \"val_loss\": avg_val_loss,\n",
        "        }, ckpt_path)\n",
        "        print(f\"✅ Best model updated at epoch {epoch+1} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "# Loss 곡선 그리기\n",
        "plt.plot(losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training & Validation Loss Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4iYdNXvjyy7",
        "outputId": "55b94193-a836-4658-e405-832ab7253dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3039\n",
            "Epoch 2, Loss: 0.3272\n",
            "✅ Best model updated at epoch 2 | Val Loss: 1.2269\n",
            "Epoch 3, Loss: 0.3084\n",
            "✅ Best model updated at epoch 3 | Val Loss: 1.1841\n",
            "Epoch 4, Loss: 0.2928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    for images, _ in test_loader:\n",
        "        x1 = images.to(device)\n",
        "        x0 = torch.randn_like(x1).to(device)\n",
        "        t = torch.rand(len(x1), 1).to(device)\n",
        "        t = t.view(-1, 1, 1, 1).expand(-1, x1.shape[1], x1.shape[2], x1.shape[3])\n",
        "\n",
        "        loss = flow_matching_loss(model, x0, x1, t)\n",
        "        total_loss += loss.item() * len(x1)\n",
        "        count += len(x1)\n",
        "    print(\"Test Loss:\", total_loss / count)"
      ],
      "metadata": {
        "id": "o5_LWacQH0_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchdiffeq import odeint\n",
        "\n",
        "def sample_images(model, n_samples=16, steps=20, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.randn(n_samples, 3, 32, 32).to(device)\n",
        "\n",
        "        def ode_func(t, x_flat):\n",
        "            x = x_flat.view(n_samples, 3, 32, 32)\n",
        "            t_tensor = torch.full((n_samples,1), t.item(), device=device)\n",
        "            t_tensor = t_tensor.view(-1,1,1,1).expand(x.shape[0],1,x.shape[2],x.shape[3])\n",
        "            dx = model(x, t_tensor)   # (B,3,32,32)\n",
        "            return dx.view(-1)        # flatten\n",
        "\n",
        "        ts = torch.linspace(0,1,steps).to(device)\n",
        "        x_final = odeint(ode_func, x.view(-1), ts)\n",
        "        x_final = x_final[-1].view(n_samples, 3, 32, 32)\n",
        "\n",
        "    return x_final.cpu()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "samples = sample_images(model, n_samples=8)\n",
        "\n",
        "fig, axes = plt.subplots(1, 8, figsize=(16,2))\n",
        "for i, ax in enumerate(axes):\n",
        "    img = samples[i].permute(1,2,0).numpy()\n",
        "    img = (img - img.min())/(img.max()-img.min())  # normalize to [0,1]\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3NWJdRPxIE64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model load**"
      ],
      "metadata": {
        "id": "LScTRSGKkujB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = torch.load(\"./checkpoints/checkpoint_epoch_100.pth\", map_location=device)\n",
        "\n",
        "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
        "start_epoch = ckpt[\"epoch\"]\n",
        "print(f\"🔄 Resumed from epoch {start_epoch}, last loss = {ckpt['loss']:.4f}\")"
      ],
      "metadata": {
        "id": "PoQzZU7Lkxmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}